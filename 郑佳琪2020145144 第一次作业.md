MapReduce预习报告
 一、MapReduce定义及核心思想
 MapReduce是一种用于在大型商用硬件集群中（成千上万的结点）对海量数据（多个兆字节数据集）实施可靠的、高容错的分布式计算的框架，也是一种经典的并行计算模型。
 MapReduce是一种分布式计算框架，以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。主要用于搜索领域，解决海量数据的计算问题。
 MapReduce的核心思想就是“分而治之”。
 二、MapReduce编程模型
  2.1MapReduce编程模型简介
  MapReduce是一种思想或者是一种编程模型。对Hadooop来说，MapReduce是一个分布式计算框架，是它的一个基础组件。当配置好Hadoop集群时，MapReduce已包含在内。
  （1）MapReduce简单模型
  对于某些任务来说，可能并不一定能需要Reduce过程，如只需要对文本的每一行数据作简单的格式转换即可，那么只需要由Mapper处理后就可以了。
  （2）MapReduce复杂模型
  对于大部分的任务来说，都需要Reduce过程，并且由于任务繁重，会启动多个Reducer来进行汇总。如果只用一个Reducer计算所有Mapper的结果，会导致单个Reduce负载过于繁重，成为性能的瓶颈，大大增加任务的运行周期。
  2.2MapReduce编程实例
  计算学生的平均成绩，每个文件包括所有的学生成绩，格式为 姓名 成绩，有多少个科目，就有多少个输入文件。

如下

小明 23 
小强 57
小红 80
小飞 93
小刚 32
小木 99
实现代码：

import java.io.IOException;
import java.util.Iterator;
import java.util.StringTokenizer;
 
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.FloatWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
 
/**
 * 计算学生的平均成绩
 * 学生成绩以每科一个文件输入
 * 文件内容为：姓名 成绩
 * @author daT dev.tao@gmail.com
 *
 */
public class AverageScore {
	
	public static class AverageMapper extends Mapper<Object, Text, Text, FloatWritable>{
		
		@Override
		protected void map(Object key, Text value, Context context)
				throws IOException, InterruptedException {
			String line = value.toString();
			StringTokenizer tokens = new StringTokenizer(line,"\n");
			while(tokens.hasMoreTokens()){
				String tmp = tokens.nextToken();
				StringTokenizer sz = new StringTokenizer(tmp);
				String name = sz.nextToken();
				float score = Float.valueOf(sz.nextToken());
				Text outName = new Text(name);//new新的,set老是不对，具体为什么现在也不太清楚。
				FloatWritable outScore  = new FloatWritable(score);
				context.write(outName, outScore);
			}
		}
		
	}
	
	public static class AverageReducer extends Reducer<Text, FloatWritable, Text, FloatWritable>{
		@Override
		protected void reduce(Text key, Iterable<FloatWritable> value,Context context)
				throws IOException, InterruptedException {
			float sum = 0;
			int count = 0;
			for(FloatWritable f:value){
				sum += f.get();
				count ++;//shuffle之后肯定是<名字,<成绩1，成绩2，成绩3....>>故一个value肯定是一门学科
			}
			FloatWritable averageScore = new FloatWritable(sum/count);new新的,set老是不对，具体为什么现在也不太清楚。
			context.write(key, averageScore);
		}
		
	}
	
	
	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException{
		System.out.println("Begin");
		Configuration conf = new Configuration();
		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
		if(otherArgs.length<2){
			System.out.println("please input at least 2 arguments");
			System.exit(2);
		}
		
		Job job = new Job(conf,"Average Score");
		job.setJarByClass(AverageScore.class);
		job.setMapperClass(AverageMapper.class);
		job.setCombinerClass(AverageReducer.class);
		job.setReducerClass(AverageReducer.class);
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(FloatWritable.class);
		
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
		
		System.exit(job.waitForCompletion(true)?0:1);
		
		System.out.println("End");
	}
	
}
配置输入输出参数：

hdfs://localhost:9000/user/dat/average_score_input hdfs://localhost:9000/user/dat/average_score_output

得到输出结果：
小刚 65.333336
小强 80.333336
小明 48.333332
小木 92.333336
小红 83.333336
小飞 83.0
三、MapReduce数据流
从MapReduce的编程模型中可以发现，数据以不同的形式在不同结点之间流动，即经过本结点的分析处理，以另外一种形式进入下一个结点，从而得出最终结果。
 3.1 分片、格式化数据源（InputFormat)
 InputFormat主要有两个任务，一个是对源文件进行分片，并确定Mapper的数量；另一个是对各分片进行格式化，处理成<key,value>形式的数据流并传给Mapper。
 3.2 Map过程
 Mapper接收<key,value>形式的数据，并处理成<key,value>形式的数据，具体的处理过程可由用户定义。
 3.3 Combiner过程
 每一个map（）都可能会产生大量的本地输出，Combiner()的作用就是对map()端的输出先做一次合并，以减少在Map和Reduce结点之间的数据传输量，提高网络I/O性能，是MapReduce的一种优化手段之一。
 3.4 Shuffle过程
 Shuffle过程是指从Mapper产生的直接输出结果，经过一系列的处理，成为最终的Reduce直接输入数据为止的整个过程，这一过程也是MapReduce的核心过程。
 3.5 Reduce过程
 Reduce接收<key,{value list}>形式的数据流，形成<key,value>形式的数据输出，输出数据直接写入HDFS，具体的处理过程可由用户定义。
  
 



